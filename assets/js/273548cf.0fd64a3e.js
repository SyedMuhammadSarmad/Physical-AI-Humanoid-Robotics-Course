"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[1309],{8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var i=n(6540);const o={},r=i.createContext(o);function a(e){const t=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(r.Provider,{value:t},e.children)}},8562:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"part2/chapter5","title":"Chapter 5: Computer Vision in Robotics","description":"Computer Vision is a field of artificial intelligence that enables computers and systems to derive meaningful information from digital images, videos, and other visual inputs \u2014 and take actions or make recommendations based on that information. For robots, computer vision is the primary sense that allows them to perceive and understand the world around them.","source":"@site/docs/part2/chapter5.md","sourceDirName":"part2","slug":"/part2/chapter5","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/part2/chapter5","draft":false,"unlisted":false,"editUrl":"https://github.com/SyedMuhammadSarmad/Physical-AI-Humanoid-Robotics-Course/tree/main/docs/docs/part2/chapter5.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Basics of AI and Machine Learning for Robotics","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/part1/chapter4"},"next":{"title":"Chapter 6: Reinforcement Learning for Physical AI","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/part2/chapter6"}}');var o=n(4848),r=n(8453);const a={sidebar_position:1},s="Chapter 5: Computer Vision in Robotics",c={},d=[{value:"Key Concepts in Computer Vision",id:"key-concepts-in-computer-vision",level:2},{value:"Applications of Computer Vision in Robotics",id:"applications-of-computer-vision-in-robotics",level:2},{value:"Code Example: Object Detection with OpenCV",id:"code-example-object-detection-with-opencv",level:3},{value:"References",id:"references",level:3}];function l(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"chapter-5-computer-vision-in-robotics",children:"Chapter 5: Computer Vision in Robotics"})}),"\n",(0,o.jsx)(t.p,{children:"Computer Vision is a field of artificial intelligence that enables computers and systems to derive meaningful information from digital images, videos, and other visual inputs \u2014 and take actions or make recommendations based on that information. For robots, computer vision is the primary sense that allows them to perceive and understand the world around them."}),"\n",(0,o.jsx)(t.h2,{id:"key-concepts-in-computer-vision",children:"Key Concepts in Computer Vision"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Image Classification"}),': The task of assigning a label or class to an entire image. For example, an image could be classified as "cat," "dog," or "car."']}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Object Detection"}),": The task of identifying and locating objects within an image. This is a more complex task than image classification, as it involves not only identifying the object but also drawing a bounding box around it."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Image Segmentation"}),": The task of partitioning an image into multiple segments or regions. This can be used to identify objects, as well as to separate the foreground from the background."]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"applications-of-computer-vision-in-robotics",children:"Applications of Computer Vision in Robotics"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Navigation and Mapping"}),": Robots use computer vision to build maps of their environment and to navigate through it. This is often done using a technique called Simultaneous Localization and Mapping (SLAM), where the robot simultaneously builds a map and keeps track of its own location within that map."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Object Recognition and Manipulation"}),": Robots use computer vision to recognize objects and to manipulate them. For example, a robot in a factory might use computer vision to identify a specific part on a conveyor belt and to pick it up and place it in the correct location."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Human-Robot Interaction"}),": Robots use computer vision to recognize and track humans, and to understand their gestures and facial expressions. This is crucial for robots that need to interact with humans in a safe and natural way."]}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"code-example-object-detection-with-opencv",children:"Code Example: Object Detection with OpenCV"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"import cv2\r\n\r\n# Load the pre-trained model\r\nnet = cv2.dnn.readNetFromCaffe('deploy.prototxt.txt', 'res10_300x300_ssd_iter_140000.caffemodel')\r\n\r\n# Load the image\r\nimage = cv2.imread('your_image.jpg')\r\n(h, w) = image.shape[:2]\r\nblob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\r\n\r\n# Pass the blob through the network and obtain the detections\r\nnet.setInput(blob)\r\ndetections = net.forward()\r\n\r\n# Loop over the detections\r\nfor i in range(0, detections.shape[2]):\r\n    confidence = detections[0, 0, i, 2]\r\n\r\n    # Filter out weak detections\r\n    if confidence > 0.5:\r\n        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\r\n        (startX, startY, endX, endY) = box.astype(\"int\")\r\n\r\n        # Draw the bounding box\r\n        text = \"{:.2f}%\".format(confidence * 100)\r\n        y = startY - 10 if startY - 10 > 10 else startY + 10\r\n        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\r\n        cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\r\n\r\n# Show the output image\r\ncv2.imshow(\"Output\", image)\r\ncv2.waitKey(0)\n"})}),"\n",(0,o.jsx)(t.h3,{id:"references",children:"References"}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGG2FhfnDLwMyAZ8RlbN-sJEK_WGJY_A9QvkhmD2Is6RuKn2vpPJI1H_S8zXztwCANo7uzmNMFTFpdGCMWT26lw1Z8AqPzatoxR8249qMg7rLX_L9h-K-phcgXE1_Us2P9LYjRK69TOMCPmE-84x1j09FAr9AvVz6I2k34i9n-ab6MqfJ5iAniXuTN_FIwOr9uTsPtDL1c=",children:"TutorialsPoint - Computer Vision"})}),"\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEk03aeuNiZKLVTB_3LFnmBGC1c-SINBKoiaAD8KdPC8QNJEJHBEe7UwQOwCSZ9HKaDAoUFNskjy5d8pVXz9jy2l3BwoQnXRYo3Npo_C2KCF02KZqzABTs9yel-tN6qo6_VtIpD9Ci7fobzhoObk8gCjYLf8Ow7fqCgLDIZIYrjDTKgFmyXnyvEPA==",children:"GeeksForGeeks - AI and Robotics"})}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);