"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[2696],{3146:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"part3/chapter11","title":"Chapter 11: Robot Localization and Mapping","description":"For a robot to operate autonomously, it must be able to answer two fundamental questions: \\"Where am I?\\" and \\"What does the world around me look like?\\". The tasks of answering these questions are known as localization and mapping, respectively.","source":"@site/docs/part3/chapter11.md","sourceDirName":"part3","slug":"/part3/chapter11","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/part3/chapter11","draft":false,"unlisted":false,"editUrl":"https://github.com/SyedMuhammadSarmad/Physical-AI-Humanoid-Robotics-Course/tree/main/docs/docs/part3/chapter11.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 10: Robot Actuators and Sensors","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/part3/chapter10"},"next":{"title":"Chapter 12: A Deep Dive into Physical AI and Humanoid Robotics","permalink":"/Physical-AI-Humanoid-Robotics-Course/docs/part4/chapter12"}}');var a=i(4848),o=i(8453);const s={sidebar_position:4},r="Chapter 11: Robot Localization and Mapping",l={},c=[{value:"Localization",id:"localization",level:2},{value:"Mapping",id:"mapping",level:2},{value:"Simultaneous Localization and Mapping (SLAM)",id:"simultaneous-localization-and-mapping-slam",level:2},{value:"Code Example: Simple Particle Filter for Localization",id:"code-example-simple-particle-filter-for-localization",level:3},{value:"References",id:"references",level:3}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"chapter-11-robot-localization-and-mapping",children:"Chapter 11: Robot Localization and Mapping"})}),"\n",(0,a.jsx)(n.p,{children:'For a robot to operate autonomously, it must be able to answer two fundamental questions: "Where am I?" and "What does the world around me look like?". The tasks of answering these questions are known as localization and mapping, respectively.'}),"\n",(0,a.jsx)(n.h2,{id:"localization",children:"Localization"}),"\n",(0,a.jsx)(n.p,{children:"Localization is the problem of determining the position and orientation of a robot within a known map. This is a crucial capability for any mobile robot, as it allows the robot to navigate to a desired location and to perform tasks that require knowledge of its own position."}),"\n",(0,a.jsx)(n.p,{children:"There are several approaches to robot localization:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dead Reckoning"}),": This is the simplest approach to localization, where the robot estimates its position by integrating its velocity over time. This approach is prone to drift, as small errors in the velocity measurements can accumulate over time."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Probabilistic Localization"}),": These methods use a probabilistic representation of the robot's position, such as a Gaussian distribution or a set of particles. The robot updates its position estimate by combining information from its sensors with a map of the environment."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Landmark-Based Localization"}),": This approach uses landmarks in the environment to determine the robot's position. The robot identifies landmarks using its sensors and then uses the known positions of the landmarks to calculate its own position."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"mapping",children:"Mapping"}),"\n",(0,a.jsx)(n.p,{children:"Mapping is the problem of creating a map of an unknown environment. This is a challenging problem, as the robot must simultaneously explore the environment and build a consistent map."}),"\n",(0,a.jsx)(n.p,{children:"There are two main types of maps used in robotics:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Feature-Based Maps"}),": These maps represent the environment as a set of features, such as points, lines, and planes."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Grid-Based Maps"}),": These maps represent the environment as a grid of cells, where each cell is either occupied or free."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"simultaneous-localization-and-mapping-slam",children:"Simultaneous Localization and Mapping (SLAM)"}),"\n",(0,a.jsx)(n.p,{children:"Simultaneous Localization and Mapping (SLAM) is the problem of simultaneously building a map of an unknown environment and localizing the robot within that map. This is a fundamental problem in robotics, and it is the key to creating truly autonomous robots."}),"\n",(0,a.jsx)(n.p,{children:"There are several approaches to SLAM, including:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Kalman Filter-Based SLAM"}),": This approach uses a Kalman filter to estimate the position of the robot and the positions of the landmarks in the environment."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Particle Filter-Based SLAM"}),": This approach uses a particle filter to represent the probability distribution of the robot's position and the map."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Graph-Based SLAM"}),": This approach represents the SLAM problem as a graph, where the nodes represent the robot's poses and the landmarks, and the edges represent the constraints between them."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"code-example-simple-particle-filter-for-localization",children:"Code Example: Simple Particle Filter for Localization"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\n\r\ndef particle_filter(particles, weights, measurement, landmarks):\r\n    """\r\n    A simple particle filter for localization.\r\n    """\r\n    # Prediction step\r\n    # Move particles according to motion model (not shown)\r\n\r\n    # Update step\r\n    for i, p in enumerate(particles):\r\n        # Calculate the distance to the nearest landmark\r\n        distances = [np.linalg.norm(p - l) for l in landmarks]\r\n        min_dist = np.min(distances)\r\n\r\n        # Update the weight of the particle based on the measurement\r\n        weights[i] *= np.exp(-0.5 * (min_dist - measurement)**2)\r\n\r\n    # Resampling step\r\n    indices = np.random.choice(len(particles), size=len(particles), p=weights/np.sum(weights))\r\n    particles = particles[indices]\r\n    weights = np.ones(len(particles)) / len(particles)\r\n\r\n    return particles, weights\r\n\r\n# Example usage\r\nnum_particles = 1000\r\nparticles = np.random.rand(num_particles, 2) * 10\r\nweights = np.ones(num_particles) / num_particles\r\nlandmarks = np.array([[2, 2], [8, 8], [2, 8], [8, 2]])\r\nmeasurement = 1.0 # a simulated measurement\r\n\r\nparticles, weights = particle_filter(particles, weights, measurement, landmarks)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHIohRdeoCvK-NvlUyuO1Mb4yiUSJEN06hm_9Et-5kRsxjwkqZDnqWa7W7vkbo2mzR1RZz2hCDLNaTXTJyWt-1oWwOm8HfEGwwvWPED96binsPPDO4Fvv2wq1NV6UQjAGXp",children:"MDPI - A Review of Simultaneous Localization and Mapping for Robotic-Based Nondestructive Evaluation of Infrastructures"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEaYsvUWBd4KsxiuR2zudbtwjjKV-hSvIlGn1yaDb8rUM7z9kZx5bZlyg1qgLyUDjC9mOR8QAZyG4y1CpKVFsDnCVDo4MLnlASWQZgRzrToBEhC388QnVqwrBxQzbbNCmY_F3aITWQ=",children:"IEEE - Review on simultaneous localization and mapping (SLAM)"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>r});var t=i(6540);const a={},o=t.createContext(a);function s(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);